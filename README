# Fine-tuning Federado de Modelos de Linguagem na Era da Comunicação
Allan M. de Souza (UNICAMP), Joahannes B. D. da Costa (UNIFESP), Daniel Guidoni (UFOP),
Gabriel Talasso (UNICAMP), Filipe Maciel (UNICAMP), Luis F. G. Gonzalez (UNICAMP), Eduardo Cerqueira (UFPA), Luiz F. Bittencourt (UNICAMP), Antonio A. F. Loureiro (UFMG), Leandro A. Villas (UNICAMP)

---

**Resumo**: *Este minicurso apresenta os fundamentos e avanços do fine-tuning federado de modelos de linguagem de grande escala (LLMs), uma abordagem que combina especialização de modelos com preservação da privacidade e descentralização dos dados. O aprendizado federado (FL) permite o treinamento de LLMs diretamente nos dispositivos onde os dados são gerados, evitando sua centralização. Técnicas de Parameter Efficient Fine-Tuning (PEFT), como LoRA e QLoRA, tornam esse processo viável em dispositivos com recursos limitados, reduzindo o custo computacional e o volume de dados transmitidos. São exploradas aplicações em áreas como saúde, finanças, desenvolvimento de software, redes inteligentes e computação na borda. Também são discutidos os principais desafios técnicos, incluindo heterogeneidade de dados e dispositivos, limitações de memória e comunicação e também oportunidades de pesquisa. O minicurso inclui um hands-on com o framework Flower, demonstrando na prática o ajuste federado de LLMs. O conteúdo busca capacitar os participantes para desenvolver soluções éticas, escaláveis e eficientes com IA personalizada e distribuída.*

